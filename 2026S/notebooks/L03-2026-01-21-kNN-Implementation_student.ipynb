{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ðŸš€ Setup (Run this cell first!)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. Detect if we are in Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab. Setting up environment...\")\n",
    "    \n",
    "    # 2. Define the source of your data files \n",
    "    BASE_URL = \"https://raw.githubusercontent.com/fhfarnoud/intro2ml/main/2026S/data/\"\n",
    "    \n",
    "    # 3. List the files you need\n",
    "    files_to_download = ['NBA_player_data.csv']\n",
    "    \n",
    "    # 4. Download the files\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        \n",
    "    for filename in files_to_download:\n",
    "        if not os.path.exists(f\"data/{filename}\"):\n",
    "            url = f\"{BASE_URL}{filename}\"\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            !wget -q -O data/{filename} {url}\n",
    "            \n",
    "    print(\"âœ… Setup complete! Data files are ready.\")\n",
    "else:\n",
    "    print(\"Running locally. Assuming data is already present.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe63ce",
   "metadata": {},
   "source": [
    "\n",
    "**ðŸ¤– AI Lab Partner Policy: STRICTLY Opt-In Code Generation**\n",
    "\n",
    "In this course, we treat AI tools (like ChatGPT, Gemini, Copilot) as **Lab Partners**, not solution generators. You must use the following prompt to ensure the AI acts responsibly.\n",
    "\n",
    "**1. Copy the text inside the block below**\n",
    "**2. Open your AI Assistant (Gemini, ChatGPT, etc.)**\n",
    "**3. Paste the text to set the rules for the session**\n",
    "\n",
    "> \"I am a student in an Intro to Machine Learning course. Please act as my **ML Lab Partner**.\n",
    "> \n",
    "> **Your Rules:**\n",
    "> \n",
    "> 1. **Code Generation is STRICTLY Opt-In:** You **MUST NOT** generate any runnable Python code unless my message starts with one of the specific prefixes below (`code:` or `output:`).\n",
    ">    * *Default Behavior:* If I ask 'How do I...?' or 'Help me with...', explain the strategy in English, provide pseudocode, or use illustrative examples. Do not generate runnable solution code.\n",
    "> \n",
    "> 2. **The 'code:' Trigger (Logic & Calculation):** \n",
    ">    * When generating code, prioritize simplicity and human readability. Avoid complex syntax.\n",
    ">    * **Constraint:** When I use this trigger, provide **only one single line of code**. Do not write full blocks.\n",
    "> \n",
    "> 3. **The 'output:' Trigger (Formatting & Printing):**\n",
    ">    * Use this ONLY when I request code to print results, format tables, or create plots.\n",
    ">    * **Exception:** For this trigger only, you **MAY** provide full multi-line code blocks to handle the verbose syntax of formatting or plotting.\n",
    "> \n",
    "> 4. **Wait for Me:** After providing the code, stop immediately. Wait for me to run it and ask for the next step.\n",
    "> \n",
    "> 5. **Explain Briefly:** Add a short comment explaining what the code does.\n",
    "> \n",
    "> 6. **Catch Logic Errors:** If I ask for a step that is methodologically wrong (like testing on training data), stop me and explain the error before proceeding.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: kNN Implementation & Real Datasets\n",
    "\n",
    "**ECE 2410 - Introduction to Machine Learning**  \n",
    "**Spring 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## Building on Lecture 2\n",
    "\n",
    "In L02, you learned:\n",
    "- Euclidean distance using `np.linalg.norm()`\n",
    "- 1-Nearest Neighbor on a small toy dataset\n",
    "- Using for loops to classify test points\n",
    "\n",
    "**Today we'll extend this to:**\n",
    "1. Real datasets with hundreds/thousands of samples\n",
    "2. Proper train/test splitting\n",
    "3. Feature normalization\n",
    "4. k-NN (majority vote among k neighbors)\n",
    "5. MNIST digit classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:36.653958Z",
     "iopub.status.busy": "2026-01-21T18:22:36.653727Z",
     "iopub.status.idle": "2026-01-21T18:22:45.885672Z",
     "shell.execute_reply": "2026-01-21T18:22:45.884928Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NEW: pandas is a library for loading and manipulating tabular data (like spreadsheets)\n",
    "import pandas as pd\n",
    "\n",
    "# NEW: sklearn has built-in datasets and ML utilities\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Python Concepts You'll Need Today\n",
    "\n",
    "Before diving into the main content, let's quickly review some Python/NumPy concepts we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.889101Z",
     "iopub.status.busy": "2026-01-21T18:22:45.888745Z",
     "iopub.status.idle": "2026-01-21T18:22:45.894903Z",
     "shell.execute_reply": "2026-01-21T18:22:45.894381Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. Random Seed for Reproducibility ---\n",
    "# Computers generate \"pseudo-random\" numbers starting from a \"seed\".\n",
    "# By fixing this seed (e.g., to 42), we ensure that every time we run this notebook,\n",
    "# we get exactly the same random shuffles and splits. Use this for debugging!\n",
    "#\n",
    "# Note: If you run a cell multiple times, you may get different results unless you reset the seed.\n",
    "# IMPORTANT: \"Restart Kernel and Run All\" to see what we will see when grading!\n",
    "\n",
    "np.random.seed(0)\n",
    "print(\"With seed 0:\", np.random.randint(0, 100, 5))\n",
    "print(\"Again:      \", np.random.randint(0, 100, 5))  # Different! Seed not reset\n",
    "\n",
    "np.random.seed(0)  # Reset to same seed\n",
    "print(\"Reset seed: \", np.random.randint(0, 100, 5))  # Same as first output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.931692Z",
     "iopub.status.busy": "2026-01-21T18:22:45.931434Z",
     "iopub.status.idle": "2026-01-21T18:22:45.935700Z",
     "shell.execute_reply": "2026-01-21T18:22:45.935242Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. Functions with Multiple Return Values ---\n",
    "# A function can return multiple values as a tuple.\n",
    "# You can \"unpack\" them directly into separate variables.\n",
    "\n",
    "def get_stats(arr):\n",
    "    return np.min(arr), np.max(arr), np.mean(arr)\n",
    "\n",
    "data = np.array([1, 5, 3, 9, 2])\n",
    "\n",
    "# Unpack the 3 returned values into 3 variables:\n",
    "min_val, max_val, mean_val = get_stats(data)\n",
    "print(f\"Min: {min_val}, Max: {max_val}, Mean: {mean_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.938200Z",
     "iopub.status.busy": "2026-01-21T18:22:45.937984Z",
     "iopub.status.idle": "2026-01-21T18:22:45.942574Z",
     "shell.execute_reply": "2026-01-21T18:22:45.942140Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. The axis Parameter ---\n",
    "# For 2D arrays: axis=0 means \"down columns\", axis=1 means \"across rows\"\n",
    "\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "print(\"X =\")\n",
    "print(X)\n",
    "print()\n",
    "print(\"Sum all:\", np.sum(X))           # 21 (everything)\n",
    "print(\"Sum axis=0:\", np.sum(X, axis=0))  # [5, 7, 9] (down columns)\n",
    "print(\"Sum axis=1:\", np.sum(X, axis=1))  # [6, 15] (across rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.944831Z",
     "iopub.status.busy": "2026-01-21T18:22:45.944636Z",
     "iopub.status.idle": "2026-01-21T18:22:45.948792Z",
     "shell.execute_reply": "2026-01-21T18:22:45.948294Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 4. Reshape ---\n",
    "# Convert between 1D vectors and 2D arrays (crucial for images!)\n",
    "\n",
    "# A 1D vector of 12 elements\n",
    "vec = np.arange(12)\n",
    "print(\"1D vector:\", vec)\n",
    "\n",
    "# Reshape to 3x4\n",
    "matrix = vec.reshape(3, 4)\n",
    "print(\"\\nReshaped to 3x4:\")\n",
    "print(matrix)\n",
    "\n",
    "# Reshape back to 1D\n",
    "flat = matrix.reshape(-1)  # -1 means \"figure out the size\"\n",
    "print(\"\\nFlattened back:\", flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.951081Z",
     "iopub.status.busy": "2026-01-21T18:22:45.950895Z",
     "iopub.status.idle": "2026-01-21T18:22:45.954906Z",
     "shell.execute_reply": "2026-01-21T18:22:45.954458Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. Views vs Copies (Important!) ---\n",
    "# Basic slicing creates a VIEW (shares memory with original)\n",
    "# Fancy indexing creates a COPY (independent)\n",
    "\n",
    "original = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# VIEW: basic slicing\n",
    "view = original[:3]\n",
    "view[0] = 999\n",
    "print(\"After modifying view:\", original)  # Original is also changed!\n",
    "\n",
    "# COPY: fancy indexing (using a list or array of indices)\n",
    "original = np.array([1, 2, 3, 4, 5])\n",
    "indices = [0, 1, 2]\n",
    "copy = original[indices]\n",
    "copy[0] = 999\n",
    "print(\"After modifying copy:\", original)  # Original unchanged!\n",
    "\n",
    "# Tip: Use .copy() if you want to be explicit\n",
    "safe_copy = original[:3].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: NBA Player Classification (Full Dataset)\n",
    "\n",
    "In L02, we used just 4 training players. Now let's use the **full NBA dataset**!\n",
    "\n",
    "**Task**: Classify NBA players as Guards vs. Forwards/Centers based on height and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the NBA Dataset\n",
    "\n",
    "**NEW: `pd.read_csv()`** - Loads data from a CSV file into a DataFrame (like a spreadsheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.957300Z",
     "iopub.status.busy": "2026-01-21T18:22:45.957107Z",
     "iopub.status.idle": "2026-01-21T18:22:45.992280Z",
     "shell.execute_reply": "2026-01-21T18:22:45.991831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load NBA data from CSV file\n",
    "nba_df = pd.read_csv('data/NBA_player_data.csv')\n",
    "print(f\"Dataset has {len(nba_df)} rows\")\n",
    "nba_df.head()  # Show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.994609Z",
     "iopub.status.busy": "2026-01-21T18:22:45.994399Z",
     "iopub.status.idle": "2026-01-21T18:22:45.997182Z",
     "shell.execute_reply": "2026-01-21T18:22:45.996715Z"
    }
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLAB SETUP\n",
    "# OPTION 1: Mount Google Drive\n",
    "# ---------------------------\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd \"/content/drive/MyDrive/Your/Notebook/Path/Here\"\n",
    "# \n",
    "# OPTION 2: Upload Data File\n",
    "# ---------------------------\n",
    "# If you prefer not to mount your drive, you can upload the data file manually.\n",
    "# The code below will upload file and move it to the correct folder.\n",
    "# \n",
    "# from google.colab import files\n",
    "# import os\n",
    "# uploaded = files.upload()\n",
    "# if not os.path.exists('data'):\n",
    "#     os.makedirs('data')\n",
    "# !mv NBA_player_data.csv data/\n",
    "# \n",
    "# Check if data exists\n",
    "# Use !ls data to check if you can see 'NBA_player_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Preprocessing\n",
    "\n",
    "Real data often needs cleaning. Here we:\n",
    "1. Convert height from \"6-8\" format to inches\n",
    "2. Remove players with missing data\n",
    "3. Simplify to 2 classes: Guard vs Forward/Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:45.999534Z",
     "iopub.status.busy": "2026-01-21T18:22:45.999343Z",
     "iopub.status.idle": "2026-01-21T18:22:46.002809Z",
     "shell.execute_reply": "2026-01-21T18:22:46.002373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert height string \"6-8\" to total inches\n",
    "def height_to_inches(h):\n",
    "    try:\n",
    "        parts = [int(p) for p in h.split('-')]  # Split \"6-8\" into [6, 8]\n",
    "        # YOUR CODE HERE\n",
    "        ## Calculate total inches from feet and inches\n",
    "        return ...  # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "print(f\"Example: '6-8' = {height_to_inches('6-8')} inches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.005245Z",
     "iopub.status.busy": "2026-01-21T18:22:46.005057Z",
     "iopub.status.idle": "2026-01-21T18:22:46.020017Z",
     "shell.execute_reply": "2026-01-21T18:22:46.019578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the data using a simple loop\n",
    "nba_df = nba_df.dropna(subset=['weight', 'height'])  # Remove missing values\n",
    "\n",
    "# Convert heights using a loop (clear and simple!)\n",
    "height_inches = []\n",
    "for h in nba_df['height']:\n",
    "    height_inches.append(height_to_inches(h))\n",
    "nba_df['height_inches'] = height_inches\n",
    "\n",
    "# Remove invalid heights\n",
    "nba_df = nba_df[nba_df['height_inches'] > 0]\n",
    "\n",
    "# Create binary classes using a loop\n",
    "classes = []\n",
    "for pos in nba_df['position']:\n",
    "    if pos == 'G':\n",
    "        classes.append('Guard')\n",
    "    elif pos in ['F', 'C', 'F-C', 'C-F']:\n",
    "        classes.append('Forward/Center')\n",
    "    else:\n",
    "        classes.append('Other')\n",
    "nba_df['class'] = classes\n",
    "\n",
    "# YOUR CODE HERE\n",
    "## # Filter out 'Other' rows - keep only Guard and Forward/Center\n",
    "nba_df = nba_df[...]  # YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Final dataset: {len(nba_df)} players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.022505Z",
     "iopub.status.busy": "2026-01-21T18:22:46.022315Z",
     "iopub.status.idle": "2026-01-21T18:22:46.026553Z",
     "shell.execute_reply": "2026-01-21T18:22:46.026099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features (X) and labels (y) as numpy arrays\n",
    "X = np.column_stack([nba_df['height_inches'].values, nba_df['weight'].values])\n",
    "y = (nba_df['class'] == 'Forward/Center').astype(int).values  # 0=Guard, 1=Fwd/Ctr\n",
    "\n",
    "print(f\"Features X: {X.shape}  (samples Ã— features)\")\n",
    "print(f\"Labels y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train/Test Split\n",
    "\n",
    "**NEW: `np.random.permutation(N)`** - Returns shuffled indices [0, 1, ..., N-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.028990Z",
     "iopub.status.busy": "2026-01-21T18:22:46.028793Z",
     "iopub.status.idle": "2026-01-21T18:22:46.033730Z",
     "shell.execute_reply": "2026-01-21T18:22:46.033296Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split data into training and test sets.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    N = len(y)\n",
    "    n_test = int(N * test_size)\n",
    "    \n",
    "    # NEW: shuffle indices randomly\n",
    "    indices = np.random.permutation(N)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    ## # Use slicing to split indices into test and train\n",
    "    test_indices = indices[...]   # first n_test indices\n",
    "    train_indices = indices[...]  # remaining indices\n",
    "    ## \n",
    "    ## # Return: X_train, X_test, y_train, y_test\n",
    "    return ..., ..., ..., ...\n",
    "    raise NotImplementedError()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(f\"Train: {len(y_train)}, Test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature Normalization\n",
    "\n",
    "**NEW: `np.std()`** - Computes standard deviation (measures spread of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.036088Z",
     "iopub.status.busy": "2026-01-21T18:22:46.035899Z",
     "iopub.status.idle": "2026-01-21T18:22:46.042004Z",
     "shell.execute_reply": "2026-01-21T18:22:46.041473Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_zscore(X_train, X_test):\n",
    "    \"\"\"Z-score: (x - mean) / std. Use TRAINING stats for both!\"\"\"\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)  # NEW: standard deviation\n",
    "    \n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std  # Use training stats!\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "X_train_norm, X_test_norm = normalize_zscore(X_train, X_test)\n",
    "print(f\"Normalized mean: {np.mean(X_train_norm, axis=0).round(4)}\")\n",
    "print(f\"Normalized std:  {np.std(X_train_norm, axis=0).round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 k-NN Implementation\n",
    "\n",
    "Uses `np.linalg.norm()` and `np.argsort()` from L02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.044553Z",
     "iopub.status.busy": "2026-01-21T18:22:46.044284Z",
     "iopub.status.idle": "2026-01-21T18:22:46.176825Z",
     "shell.execute_reply": "2026-01-21T18:22:46.176337Z"
    }
   },
   "outputs": [],
   "source": [
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"k-Nearest Neighbors prediction.\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for x_test in X_test:\n",
    "        # Distance to all training points (from L02!)\n",
    "        distances = np.linalg.norm(X_train - x_test, axis=1)\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        ## # Find k nearest neighbors\n",
    "        k_nearest_indices = ...   # indices of k smallest distances (hint: np.argsort)\n",
    "        k_nearest_labels = ...    # labels of those neighbors\n",
    "        ## \n",
    "        ## # Count votes for each class\n",
    "        count_class_0 = ...  # how many neighbors have label 0?\n",
    "        count_class_1 = ...  # how many neighbors have label 1?\n",
    "        ## \n",
    "        ## # Predict: which class has more votes?\n",
    "        if count_class_1 > count_class_0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "        raise NotImplementedError()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "y_pred = knn_predict(X_train_norm, y_train, X_test_norm, k=5)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Precision and Recall\n",
    "\n",
    "**Accuracy** can be misleading with imbalanced classes. Let's also compute:\n",
    "- **Precision**: Of all predicted positives, how many are correct?\n",
    "- **Recall**: Of all actual positives, how many did we find?\n",
    "\n",
    "For our NBA data: Positive class = Forward/Center (label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.179375Z",
     "iopub.status.busy": "2026-01-21T18:22:46.179160Z",
     "iopub.status.idle": "2026-01-21T18:22:46.184234Z",
     "shell.execute_reply": "2026-01-21T18:22:46.183781Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute accuracy, precision, and recall.\"\"\"\n",
    "    # True Positives, False Positives, False Negatives, True Negatives\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    ## # Compute the metrics using TP, FP, FN, TN\n",
    "    accuracy = ...   \n",
    "    precision = ...  \n",
    "    recall = ...     \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "acc, prec, rec = compute_metrics(y_test, y_pred)\n",
    "print(f\"Accuracy:  {acc:.2%}\")\n",
    "print(f\"Precision: {prec:.2%}  (of predicted Fwd/Ctr, how many correct?)\")\n",
    "print(f\"Recall:    {rec:.2%}  (of actual Fwd/Ctr, how many did we find?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: MNIST Digit Classification\n",
    "\n",
    "**Key Concept**: Images are vectors! A 28Ã—28 image = 784-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:22:46.186615Z",
     "iopub.status.busy": "2026-01-21T18:22:46.186425Z",
     "iopub.status.idle": "2026-01-21T18:23:09.792499Z",
     "shell.execute_reply": "2026-01-21T18:23:09.791975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "print(\"Loading MNIST...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X_mnist = mnist.data.astype(np.float32)\n",
    "y_mnist = mnist.target.astype(np.int32)\n",
    "print(f\"Shape: {X_mnist.shape}  (28Ã—28 = 784 pixels per image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualize: Vector â†’ Image\n",
    "\n",
    "**NEW: `arr.reshape(28, 28)`** - Changes shape from (784,) to (28, 28) for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:23:09.795330Z",
     "iopub.status.busy": "2026-01-21T18:23:09.795106Z",
     "iopub.status.idle": "2026-01-21T18:23:09.924342Z",
     "shell.execute_reply": "2026-01-21T18:23:09.923710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display first digit\n",
    "img_vector = X_mnist[0]  # 784-element vector\n",
    "img_2d = img_vector.reshape(28, 28)  # NEW: reshape to 2D\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_2d, cmap='gray')\n",
    "plt.title(f'Label: {y_mnist[0]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:23:09.926957Z",
     "iopub.status.busy": "2026-01-21T18:23:09.926733Z",
     "iopub.status.idle": "2026-01-21T18:23:09.943670Z",
     "shell.execute_reply": "2026-01-21T18:23:09.943171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare subset (full dataset is too slow for k-NN)\n",
    "X_train_mnist = X_mnist[:5000] / 255.0  # Normalize to [0,1]\n",
    "y_train_mnist = y_mnist[:5000]\n",
    "X_test_mnist = X_mnist[60000:61000] / 255.0\n",
    "y_test_mnist = y_mnist[60000:61000]\n",
    "\n",
    "print(f\"Train: {X_train_mnist.shape}, Test: {X_test_mnist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:23:09.946310Z",
     "iopub.status.busy": "2026-01-21T18:23:09.946106Z",
     "iopub.status.idle": "2026-01-21T18:23:15.707683Z",
     "shell.execute_reply": "2026-01-21T18:23:15.707143Z"
    }
   },
   "outputs": [],
   "source": [
    "def knn_multiclass(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"k-NN for multi-class (10 digits).\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i, x_test in enumerate(X_test):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing {i}/{len(X_test)}...\", end='\\r')\n",
    "        \n",
    "        # Step 1: Compute distances to all training points\n",
    "        distances = np.linalg.norm(X_train - x_test, axis=1)\n",
    "        \n",
    "        # Step 2: Find the k nearest neighbors' labels\n",
    "        k_nearest_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_nearest_indices]\n",
    "        \n",
    "        # Step 3: Count votes for each digit (0-9)\n",
    "        vote_counts = np.zeros(10, dtype=int)  # 10 possible digits\n",
    "        # YOUR CODE HERE\n",
    "        ## # Increment the vote count for each neighbor's label\n",
    "        for label in k_nearest_labels:\n",
    "            vote_counts[...] += 1  # which index to increment?\n",
    "        ## \n",
    "        ## # Step 4: Predict the digit with the most votes (hint: np.argmax)\n",
    "        prediction = ...\n",
    "        raise NotImplementedError()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    print(\"Done!\" + \" \"*20)\n",
    "    return np.array(predictions)\n",
    "\n",
    "print(\"Running k-NN (this takes ~1 minute)...\")\n",
    "y_pred_mnist = knn_multiclass(X_train_mnist, y_train_mnist, X_test_mnist, k=3)\n",
    "print(f\"MNIST Accuracy: {np.mean(y_pred_mnist == y_test_mnist):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Misclassified Examples\n",
    "\n",
    "Let's see which digits kNN got wrong. This helps us understand the model's limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T18:23:15.710468Z",
     "iopub.status.busy": "2026-01-21T18:23:15.710219Z",
     "iopub.status.idle": "2026-01-21T18:23:16.008413Z",
     "shell.execute_reply": "2026-01-21T18:23:16.007905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find misclassified examples\n",
    "misclassified_idx = np.where(y_pred_mnist != y_test_mnist)[0]\n",
    "print(f\"Number of misclassified: {len(misclassified_idx)} out of {len(y_test_mnist)}\")\n",
    "\n",
    "# Display misclassified examples with their closest training image\n",
    "n_show = 5\n",
    "fig, axes = plt.subplots(n_show, 2, figsize=(4, 10))\n",
    "axes[0, 0].set_title('Test Image', fontsize=10)\n",
    "axes[0, 1].set_title('Nearest Neighbor', fontsize=10)\n",
    "\n",
    "for row in range(n_show):\n",
    "    if row < len(misclassified_idx):\n",
    "        idx = misclassified_idx[row]\n",
    "        \n",
    "        # Test image (misclassified)\n",
    "        test_img = X_test_mnist[idx].reshape(28, 28)\n",
    "        axes[row, 0].imshow(test_img, cmap='gray')\n",
    "        axes[row, 0].set_ylabel(f'True: {y_test_mnist[idx]}', fontsize=9)\n",
    "        \n",
    "        # Find the closest training image\n",
    "        distances = np.linalg.norm(X_train_mnist - X_test_mnist[idx], axis=1)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        closest_img = X_train_mnist[closest_idx].reshape(28, 28)\n",
    "        axes[row, 1].imshow(closest_img, cmap='gray')\n",
    "        axes[row, 1].set_ylabel(f'Label: {y_train_mnist[closest_idx]}', fontsize=9)\n",
    "    \n",
    "    axes[row, 0].axis('off')\n",
    "    axes[row, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Misclassified: Test vs Nearest Neighbor', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
