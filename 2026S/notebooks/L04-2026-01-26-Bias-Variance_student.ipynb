{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Bias-Variance Tradeoff & Cross-Validation\n",
    "\n",
    "This notebook demonstrates the concepts of **Bias**, **Variance**, and **Cross-Validation** using a k-Nearest Neighbors (kNN) classifier on a synthetic dataset.\n",
    "\n",
    "## Goals:\n",
    "1.  **Visualize the Dataset**: Understand the underlying structure (Gaussian mixtures (optional)).\n",
    "2.  **Optimal Decision Boundary**: See the best possible classification boundary (Bayes Error (optional)).\n",
    "3.  **Variance**: Visualize how the decision boundary changes with different training sets.\n",
    "4.  **Hyperparameter Tuning (Holdout)**: Find optimal $k$ using a simple training/validation split.\n",
    "5.  **K-Fold Cross-Validation**: Perform robust model evaluation using `cross_val_score`.\n",
    "6.  **Error Curves**: Plot training vs validation error as $k$ changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. For in class demo (you can skip this part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Data Generation\n",
    "\n",
    "We generate a synthetic binary classification dataset using a mixture of Gaussians. This allows us to have some overlap between classes, simulating noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(params_class0, params_class1, n_samples_class0=1000, n_samples_class1=1000):\n",
    "    \"\"\"\n",
    "    Generates a dataset with two classes, each as a mixture of Gaussians.\n",
    "    \"\"\"\n",
    "    # Generate data for Class 0\n",
    "    X_class0_list = []\n",
    "    weights0 = [component['weight'] for component in params_class0]\n",
    "    total_weight0 = sum(weights0)\n",
    "    n_samples_components0 = [int(n_samples_class0 * (w / total_weight0)) for w in weights0]\n",
    "    n_samples_components0[-1] += n_samples_class0 - sum(n_samples_components0)\n",
    "    \n",
    "    for n_samples_comp, component in zip(n_samples_components0, params_class0):\n",
    "        X_comp = np.random.multivariate_normal(\n",
    "            mean=component['mean'],\n",
    "            cov=component['cov'],\n",
    "            size=n_samples_comp\n",
    "        )\n",
    "        X_class0_list.append(X_comp)\n",
    "    X_class0 = np.vstack(X_class0_list)\n",
    "    y_class0 = np.zeros(len(X_class0))\n",
    "    \n",
    "    # Generate data for Class 1\n",
    "    X_class1_list = []\n",
    "    weights1 = [component['weight'] for component in params_class1]\n",
    "    total_weight1 = sum(weights1)\n",
    "    n_samples_components1 = [int(n_samples_class1 * (w / total_weight1)) for w in weights1]\n",
    "    n_samples_components1[-1] += n_samples_class1 - sum(n_samples_components1)\n",
    "    \n",
    "    for n_samples_comp, component in zip(n_samples_components1, params_class1):\n",
    "        X_comp = np.random.multivariate_normal(\n",
    "            mean=component['mean'],\n",
    "            cov=component['cov'],\n",
    "            size=n_samples_comp\n",
    "        )\n",
    "        X_class1_list.append(X_comp)\n",
    "    X_class1 = np.vstack(X_class1_list)\n",
    "    y_class1 = np.ones(len(X_class1))\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    X = np.vstack((X_class0, X_class1))\n",
    "    y = np.hstack((y_class0, y_class1))\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Define mixture components\n",
    "params_class0 = [{'mean': [-1.25, 0], 'cov': [[1.5, 0], [0, 1]], 'weight': 1.0}]\n",
    "params_class1 = [\n",
    "    {'mean': [1.25, 0], 'cov': [[1, 0], [0, 1]], 'weight': 0.9},\n",
    "    {'mean': [-1, 3], 'cov': [[0.3, 0], [0, 0.3]], 'weight': 0.1},\n",
    "]\n",
    "\n",
    "print(\"Generating dataset...\")\n",
    "X, y = generate_data(params_class0, params_class1, n_samples_class0=500, n_samples_class1=500)\n",
    "print(f\"Dataset shape: {X.shape}, Labels: {len(y)} ({int(sum(y==0))} class 0, {int(sum(y==1))} class 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_points(X, y):\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=50, alpha=0.6)\n",
    "    plt.title('Data Points', fontsize=14)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_points(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Optimal Decision Boundary\n",
    "\n",
    "Since we know the true distributions (Gaussians), we can calculate the **Bayes Optimal Classifier**. No model can beat this performance on this specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimal_decision_boundary(params_class0, params_class1, X, y):\n",
    "    from scipy.stats import multivariate_normal\n",
    "\n",
    "    # Grid setup\n",
    "    h = 0.1\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Compute PDFs\n",
    "    def compute_pdf(params, points):\n",
    "        pdf = np.zeros(len(points))\n",
    "        total_weight = sum([comp['weight'] for comp in params])\n",
    "        for comp in params:\n",
    "            rv = multivariate_normal(mean=comp['mean'], cov=comp['cov'])\n",
    "            pdf += (comp['weight'] / total_weight) * rv.pdf(points)\n",
    "        return pdf\n",
    "\n",
    "    pdf0 = compute_pdf(params_class0, grid_points)\n",
    "    pdf1 = compute_pdf(params_class1, grid_points)\n",
    "\n",
    "    # Prediction: Class 0 if P(0) > P(1)\n",
    "    Z = np.where(pdf0 > pdf1, 0, 1).reshape(xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='auto')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=50, alpha=0.5)\n",
    "    plt.title('Optimal Decision Boundary (Bayes)', fontsize=14)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()\n",
    "\n",
    "plot_optimal_decision_boundary(params_class0, params_class1, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Visualizing Variance with Independent Training Sets\n",
    "\n",
    "We divide the data into **disjoint subsets** (no overlap) and train a separate kNN model on each. Notice how the decision boundary varies - this is **Variance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_disjoint_sets(X, y, n_sets=4):\n",
    "    \"\"\"\n",
    "    Divide data into n_sets disjoint (non-overlapping) subsets.\n",
    "    Uses random splitting to create disjoint subsets.\n",
    "    \n",
    "    Returns:\n",
    "        List of (X_subset, y_subset) tuples\n",
    "    \"\"\"\n",
    "    n_samples = len(y)\n",
    "    \n",
    "    # Shuffle indices first\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split into n_sets disjoint parts\n",
    "    set_size = n_samples // n_sets\n",
    "    subsets = []\n",
    "    \n",
    "    for i in range(n_sets):\n",
    "        start = i * set_size\n",
    "        if i == n_sets - 1:\n",
    "            end = n_samples  # Last set gets remaining samples\n",
    "        else:\n",
    "            end = start + set_size\n",
    "        \n",
    "        subset_indices = indices[start:end]\n",
    "        subsets.append((X[subset_indices], y[subset_indices]))\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "# Demonstrate the split\n",
    "subsets = divide_into_disjoint_sets(X, y, n_sets=4)\n",
    "print(f\"Divided {len(X)} samples into {len(subsets)} disjoint sets:\")\n",
    "for i, (X_sub, y_sub) in enumerate(subsets):\n",
    "    print(f\"  Set {i+1}: {len(X_sub)} samples ({int(sum(y_sub==0))} class 0, {int(sum(y_sub==1))} class 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disjoint_boundaries(X, y, k=21, n_sets=4):\n",
    "    \"\"\"\n",
    "    Plot kNN decision boundaries trained on DISJOINT (independent) subsets.\n",
    "    Each training set has NO overlap with others.\n",
    "    \"\"\"\n",
    "    subsets = divide_into_disjoint_sets(X, y, n_sets)\n",
    "    \n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    # Grid for plotting\n",
    "    h = 0.3\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    for i, (X_train, y_train) in enumerate(subsets[:4]):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        \n",
    "        ax = axs[i]\n",
    "        ax.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='auto')\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap_bold, edgecolor='k', s=50, alpha=0.5)\n",
    "        ax.set_title(f\"Independent Set {i+1} (k={k}, n={len(X_train)})\")\n",
    "        ax.set_xlabel('Feature 1')\n",
    "        ax.set_ylabel('Feature 2')\n",
    "\n",
    "    plt.suptitle(f'kNN Decision Boundaries on Disjoint Training Sets\\n', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize with k=21\n",
    "plot_disjoint_boundaries(X, y, k=1, n_sets=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Optional Activity: Compare Variance for Different k\n",
    "Run the cell below to see how variance changes with different values of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try k=1 (high variance) vs k=101 (low variance)\n",
    "print(\"=\" * 50)\n",
    "print(\"k=1: High Variance (wiggly boundaries)\")\n",
    "print(\"=\" * 50)\n",
    "plot_disjoint_boundaries(X, y, k=1, n_sets=4)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"k=101: Low Variance (smooth, stable boundaries)\")\n",
    "print(\"=\" * 50)\n",
    "plot_disjoint_boundaries(X, y, k=15, n_sets=4)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"k=101: Low Variance (smooth, stable boundaries)\")\n",
    "print(\"=\" * 50)\n",
    "plot_disjoint_boundaries(X, y, k=100, n_sets=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Hyper-parameter Tuning via Train-Val-Test Split with sklearn\n",
    "\n",
    "### KNeighborsClassifier and train_test_split\n",
    "\n",
    "We are going to tune the parameter k for kNN using the validation set approach. Let's introduce the two key functions:\n",
    "\n",
    "---\n",
    "\n",
    "### `KNeighborsClassifier()` - k-Nearest Neighbors Classifier\n",
    "\n",
    "**Purpose:** Create a k-Nearest Neighbors classifier for classification tasks.\n",
    "\n",
    "**Syntax:**\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)           # Train on training data\n",
    "predictions = clf.predict(X_test)   # Make predictions on test data\n",
    "score = clf.score(X_test, y_test)   # Compute accuracy on test data\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `train_test_split()` - Train/Val/Test Splitting\n",
    "\n",
    "**Purpose:** Split data into training, validation, and test sets.\n",
    "\n",
    "**Syntax:**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,                  # Feature matrix\n",
    "    y,                  # Target labels\n",
    "    test_size=0.2,      # Fraction for test set (0.2 = 20%)\n",
    "    random_state=42     # Random seed for reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "**Returns:** Four arrays: `X_train, X_test, y_train, y_test`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Divide the data into Train, Validation, and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# First split: 60% train, 40% temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(...)\n",
    "\n",
    "# Second split: Split temp into 50% val, 50% test (each 20% of original)\n",
    "X_val, X_test, y_val, y_test = train_test_split(...)\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Val:   {len(X_val)} samples ({len(X_val)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test:  {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nVal and Test sets will NOT be used until model selection/evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Grid Search on Validation Set\n",
    "\n",
    "We search over different values of $k$ by training on the training set and evaluating on the validation set. This finds the best hyperparameter without touching the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of k (odd numbers to avoid ties)\n",
    "k_values = np.arange(1, 100, 2)\n",
    "val_scores = []\n",
    "\n",
    "print(\"Searching for optimal k...\")\n",
    "for k in k_values:\n",
    "    # YOUR CODE HERE\n",
    "    knn = KNeighborsClassifier(...)\n",
    "    knn.fit(...)\n",
    "    accuracy = knn.score(...)\n",
    "    raise NotImplementedError()\n",
    "    val_scores.append(accuracy)\n",
    "\n",
    "val_scores = np.array(val_scores)\n",
    "best_k_idx = np.argmax(val_scores)\n",
    "best_k = k_values[best_k_idx]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, val_scores, marker='s', color='blue', label='Validation Accuracy')\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', linewidth=2, label=f'Best k={best_k}')\n",
    "plt.title('Validation Accuracy vs. k')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Validation Accuracy: {val_scores[best_k_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train Final Model and Evaluate on Test Set\n",
    "\n",
    "Now that we've selected the best $k$ using the validation set, we train a final model on the combined training+validation data with this optimal $k$, and evaluate it on the held-out test set.\n",
    "\n",
    "#### Train and Evaluate the Final Model\n",
    "\n",
    "Train a kNN classifier with best k on train+val data and evaluate on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+val and train final model\n",
    "\n",
    "X_final_train = np.vstack([X_train, X_val]) # The result will be of shape (n_train + n_val, n_features)\n",
    "y_final_train = np.hstack([y_train, y_val]) # The result will be of shape (n_train + n_val,). Using hstack ensures that y remains a vector and does not become a 2D array.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "clf_final = KNeighborsClassifier(...)\n",
    "clf_final.fit(...)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf_final.predict(...)\n",
    "test_accuracy = np.mean(...)\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"k: {best_k}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Hyper-parameter Tuning via K-Fold Cross-Validation\n",
    "\n",
    "\n",
    "We are going to tune the parameter k for kNN using k-fold cross-validation. We've already learned about `KNeighborsClassifier()` in Section 1. Now let's introduce `cross_val_score()`:\n",
    "\n",
    "### `cross_val_score()` - K-Fold Cross-Validation\n",
    "\n",
    "**Purpose:** Evaluate a model using k-fold cross-validation by computing accuracy scores across multiple folds.\n",
    "\n",
    "**Syntax:**\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    estimator,          # The model to evaluate (e.g., KNeighborsClassifier())\n",
    "    X,                  # Feature matrix\n",
    "    y,                  # Target labels\n",
    "    cv=5,               # Number of folds (default=5)\n",
    "    scoring='accuracy'  # Metric to use\n",
    ")\n",
    "```\n",
    "\n",
    "**Returns:** Array of scores, one for each fold (e.g., `[0.92, 0.88, 0.90, 0.91, 0.89]`)\n",
    "\n",
    "**How it works:**\n",
    "1. Splits data into K non-overlapping folds\n",
    "2. For each fold: trains on K-1 folds, validates on 1 fold\n",
    "3. Returns accuracy scores for each fold\n",
    "4. Average them to get robust estimate of model performance\n",
    "\n",
    "### 2.1 Cross-validation and Grid Search with K-Fold Cross-Validation\n",
    "\n",
    "We search over different values of $k$ by using 5-fold cross-validation on the training set. This finds the best hyperparameter without touching the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of k (odd numbers to avoid ties)\n",
    "k_values = np.arange(1, 100, 2)\n",
    "val_scores = []\n",
    "\n",
    "print(\"Running k-fold cross-validation for each k...\")\n",
    "for k in k_values:\n",
    "    # YOUR CODE HERE\n",
    "    knn = KNeighborsClassifier(...)\n",
    "    scores = cross_val_score(...)\n",
    "    accuracy = scores.mean()\n",
    "    raise NotImplementedError()\n",
    "    val_scores.append(accuracy)\n",
    "\n",
    "val_scores = np.array(val_scores)\n",
    "best_k_idx = np.argmax(val_scores)\n",
    "best_k = k_values[best_k_idx]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, val_scores, marker='s', color='purple', label='5-Fold CV Accuracy')\n",
    "plt.axvline(x=best_k, color='green', linestyle='--', linewidth=2, label=f'Best k={best_k}')\n",
    "plt.title('K-Fold Cross-Validation: Accuracy vs. k')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Mean CV Accuracy: {val_scores[best_k_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Train Final Model and Evaluate on Test Set\n",
    "\n",
    "Now that we've selected the best $k$ using 5-fold cross-validation on the training set, we train a final model on the full training data with this optimal $k$, and evaluate it on the held-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on training set with best k\n",
    "# YOUR CODE HERE\n",
    "clf_final = KNeighborsClassifier(...)\n",
    "clf_final.fit(...)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf_final.predict(...)\n",
    "test_accuracy = np.mean(...)\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"k: {best_k}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
