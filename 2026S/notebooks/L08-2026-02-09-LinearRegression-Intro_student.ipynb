{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca255512",
   "metadata": {},
   "source": [
    "\n",
    "**ðŸ¤– AI Lab Partner Policy: STRICTLY Opt-In Code Generation**\n",
    "\n",
    "In this course, we treat AI tools (like ChatGPT, Gemini, Copilot) as **Lab Partners**, not solution generators. You must use the following prompt to ensure the AI acts responsibly.\n",
    "\n",
    "**1. Copy the text inside the block below**\n",
    "**2. Open your AI Assistant (Gemini, ChatGPT, etc.)**\n",
    "**3. Paste the text to set the rules for the session**\n",
    "\n",
    "> \"I am a student in an Intro to Machine Learning course. Please act as my **ML Lab Partner**.\n",
    "> \n",
    "> **Your Rules:**\n",
    "> \n",
    "> 1. **Code Generation is STRICTLY Opt-In:** You **MUST NOT** generate any runnable Python code unless my message starts with one of the specific prefixes below (`code:` or `output:`).\n",
    ">    * *Default Behavior:* If I ask 'How do I...?' or 'Help me with...', explain the strategy in English, provide pseudocode, or use illustrative examples. Do not generate runnable solution code.\n",
    "> \n",
    "> 2. **The 'code:' Trigger (Logic & Calculation):** \n",
    ">    * When generating code, prioritize simplicity and human readability. Avoid complex syntax.\n",
    ">    * **Constraint:** When I use this trigger, provide **only one single line of code**. Do not write full blocks.\n",
    "> \n",
    "> 3. **The 'output:' Trigger (Formatting & Printing):**\n",
    ">    * Use this ONLY when I request code to print results, format tables, or create plots.\n",
    ">    * **Exception:** For this trigger only, you **MAY** provide full multi-line code blocks to handle the verbose syntax of formatting or plotting.\n",
    "> \n",
    "> 4. **Wait for Me:** After providing the code, stop immediately. Wait for me to run it and ask for the next step.\n",
    "> \n",
    "> 5. **Explain Briefly:** Add a short comment explaining what the code does.\n",
    "> \n",
    "> 6. **Catch Logic Errors:** If I ask for a step that is methodologically wrong (like testing on training data), stop me and explain the error before proceeding.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Introduction to Linear Regression\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load and visualize the education dataset\n",
    "2. Implement simple linear regression using the closed-form solution\n",
    "3. Compare our implementation with sklearn's LinearRegression\n",
    "4. Make predictions and plot the regression line\n",
    "5. Compute and interpret RMSE and RÂ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore the Data\n",
    "\n",
    "We'll use the Education Longitudinal Study (ELS) dataset, which contains information about high school students including their test scores and socioeconomic status.\n",
    "\n",
    "Our goal: **Predict reading scores from math scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas only for loading the .dta file; we'll work with numpy arrays\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_stata('https://raw.githubusercontent.com/fhfarnoud/intro2ml/main/2026S/data/els_small.dta')\n",
    "\n",
    "# Clean: remove rows with non-numeric values\n",
    "df = df[pd.to_numeric(df['bymath'], errors='coerce').notnull()]\n",
    "df = df[pd.to_numeric(df['byread'], errors='coerce').notnull()]\n",
    "\n",
    "# Sample for clearer visualizations\n",
    "np.random.seed(42)  # For reproducibility\n",
    "df = df.sample(n=500)\n",
    "\n",
    "# Extract as numpy arrays\n",
    "mathscore = np.array(df['bymath'].values, dtype=float)\n",
    "readscore = np.array(df['byread'].values, dtype=float)\n",
    "\n",
    "print(f\"Number of students: {len(mathscore)}\")\n",
    "print(f\"Math score range: {mathscore.min():.1f} to {mathscore.max():.1f}\")\n",
    "print(f\"Reading score range: {readscore.min():.1f} to {readscore.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between math and reading scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(mathscore, readscore, alpha=0.3, s=10)\n",
    "plt.xlabel('Math Score')\n",
    "plt.ylabel('Reading Score')\n",
    "plt.title('Reading Score vs Math Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the relationship look approximately linear? Would a line be a reasonable model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sol"
    ]
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement the Closed-Form Solution\n",
    "\n",
    "Recall from lecture, the closed-form solution for linear regression $y = ax + b$ is:\n",
    "\n",
    "$$\\hat{a} = \\frac{\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_i (x_i - \\bar{x})^2}$$\n",
    "\n",
    "$$\\hat{b} = \\bar{y} - \\hat{a} \\cdot \\bar{x}$$\n",
    "\n",
    "Let's implement this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y for our regression\n",
    "x = mathscore\n",
    "y = readscore\n",
    "\n",
    "# Compute the means\n",
    "x_bar = np.mean(x)\n",
    "y_bar = np.mean(y)\n",
    "\n",
    "print(f\"Mean math score: {x_bar:.2f}\")\n",
    "print(f\"Mean reading score: {y_bar:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Compute the slope (a) using the closed-form formula above\n",
    "numerator = ...\n",
    "denominator = ...\n",
    "a = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Slope (a): {a:.4f}\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert abs(a - 0.6901) < 0.01, f\"Expected slope ~0.69, got {a:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Compute the intercept (b) using the closed-form formula above\n",
    "b = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Intercept (b): {b:.4f}\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert abs(b - 15.4841) < 0.1, f\"Expected intercept ~15.48, got {b:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOur linear model: reading_score = {a:.4f} * math_score + {b:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - For each 1-point increase in math score, reading score increases by {a:.2f} points\")\n",
    "print(f\"  - A student with math score 0 would have predicted reading score of {b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare with sklearn's LinearRegression\n",
    "\n",
    "Let's verify our implementation by comparing with sklearn.\n",
    "\n",
    "### sklearn LinearRegression API\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()      # Create the model\n",
    "model.fit(X, y)                 # Train on data (X must be 2D)\n",
    "\n",
    "model.coef_                     # Slope(s) - array of coefficients\n",
    "model.intercept_                # Intercept (scalar)\n",
    "```\n",
    "\n",
    "**Note:** sklearn requires X to be 2D (shape `(N, D)`), even for simple regression with one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn requires 2D input, so we reshape\n",
    "X = mathscore.reshape(-1, 1)  # shape: (N, 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# TODO: Create a LinearRegression model, fit it, and extract the slope and intercept\n",
    "model = ...\n",
    "a_sklearn = ...\n",
    "b_sklearn = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"sklearn slope: {a_sklearn:.4f}\")\n",
    "print(f\"sklearn intercept: {b_sklearn:.4f}\")\n",
    "print(f\"\\nOur slope: {a:.4f}\")\n",
    "print(f\"Our intercept: {b:.4f}\")\n",
    "print(f\"\\nDifference in slope: {abs(a - a_sklearn):.10f}\")\n",
    "print(f\"Difference in intercept: {abs(b - b_sklearn):.10f}\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert abs(a - a_sklearn) < 1e-10, f\"Slope mismatch: manual={a}, sklearn={a_sklearn}\"\n",
    "assert abs(b - b_sklearn) < 1e-10, f\"Intercept mismatch: manual={b}, sklearn={b_sklearn}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values should match (up to numerical precision)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Make Predictions and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions for plotting the line\n",
    "x_line = np.array([mathscore.min(), mathscore.max()])\n",
    "y_line = a * x_line + b\n",
    "\n",
    "# Plot data and regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(mathscore, readscore, alpha=0.3, s=10, label='Data')\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=3, label=f'y = {a:.2f}x + {b:.2f}')\n",
    "plt.xlabel('Math Score')\n",
    "plt.ylabel('Reading Score')\n",
    "plt.title('Linear Regression: Reading Score vs Math Score')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "**Manual prediction:** Use the linear equation directly:\n",
    "$$\\hat{y} = a \\cdot x + b$$\n",
    "\n",
    "**sklearn prediction:**\n",
    "```python\n",
    "model.predict(X_new)    # X_new must be 2D, returns array of predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for specific math scores\n",
    "test_scores = np.array([30, 50, 70, 90])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# TODO: Compute predictions manually using a and b\n",
    "pred_manual = ...\n",
    "#\n",
    "# TODO: Compute predictions using sklearn (remember: input must be 2D)\n",
    "pred_sklearn = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Math Score':<12} {'Manual':<12} {'sklearn':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(test_scores)):\n",
    "    print(f\"{test_scores[i]:<12} {pred_manual[i]:<12.1f} {pred_sklearn[i]:<12.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Evaluation\n",
    "\n",
    "To compute evaluation metrics (RMSE, RÂ²), we need predictions for **all** data points, not just a few test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Compute predictions for all data points using a and b\n",
    "y_pred = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Generated {len(y_pred)} predictions\")\n",
    "print(f\"Prediction range: {y_pred.min():.1f} to {y_pred.max():.1f}\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert y_pred.shape == (500,), f\"Expected shape (500,), got {y_pred.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Evaluation Metrics\n",
    "\n",
    "Now let's compute RMSE and RÂ² to evaluate how well our model fits the data.\n",
    "\n",
    "**Note:** We're evaluating on the same data we trained on (no train/test split yet). This tells us how well the model fits, but not how well it generalizes to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and RMSE\n",
    "\n",
    "**MSE (Mean Squared Error):** Average of squared errors\n",
    "$$\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**RMSE (Root Mean Squared Error):** Square root of MSE\n",
    "$$\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "RMSE has the same units as y, making it interpretable as \"typical prediction error.\"\n",
    "\n",
    "**sklearn:**\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)  # Returns MSE\n",
    "rmse = np.sqrt(mse)                        # Take sqrt for RMSE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Compute RMSE manually\n",
    "SSE = ...\n",
    "N = ...\n",
    "RMSE_manual = ...\n",
    "#\n",
    "# TODO: Compute RMSE using sklearn\n",
    "RMSE_sklearn = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"RMSE (manual):  {RMSE_manual:.2f}\")\n",
    "print(f\"RMSE (sklearn): {RMSE_sklearn:.2f}\")\n",
    "print(f\"\\nInterpretation: On average, our predictions are off by about {RMSE_manual:.1f} points\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert abs(RMSE_manual - RMSE_sklearn) < 1e-10, f\"RMSE mismatch: manual={RMSE_manual}, sklearn={RMSE_sklearn}\"\n",
    "assert abs(RMSE_manual - 6.69) < 0.1, f\"Expected RMSE ~6.69, got {RMSE_manual:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RÂ² (Coefficient of Determination)\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\text{SSE}}{\\text{SST}} = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}$$\n",
    "\n",
    "RÂ² represents the fraction of variance in y explained by the model.\n",
    "\n",
    "**sklearn:**\n",
    "```python\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)  # Computes È³ and SST internally\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# TODO: Compute RÂ² manually\n",
    "SST = ...\n",
    "R2_manual = ...\n",
    "#\n",
    "# TODO: Compute RÂ² using sklearn\n",
    "R2_sklearn = ...\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"RÂ² (manual):  {R2_manual:.4f}\")\n",
    "print(f\"RÂ² (sklearn): {R2_sklearn:.4f}\")\n",
    "print(f\"\\nInterpretation: Math score explains {R2_manual*100:.1f}% of the variance in reading score\")\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "assert abs(R2_manual - R2_sklearn) < 1e-10, f\"RÂ² mismatch: manual={R2_manual}, sklearn={R2_sklearn}\"\n",
    "assert abs(R2_manual - 0.5108) < 0.01, f\"Expected RÂ² ~0.51, got {R2_manual:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Loaded** the ELS education dataset with math and reading scores\n",
    "2. **Implemented** the closed-form solution for simple linear regression:\n",
    "   - $\\hat{a} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}$\n",
    "   - $\\hat{b} = \\bar{y} - \\hat{a}\\bar{x}$\n",
    "3. **Verified** our results match sklearn's LinearRegression\n",
    "4. **Made predictions** using both manual formula and `model.predict()`\n",
    "5. **Computed evaluation metrics**:\n",
    "   - RMSE: typical prediction error (same units as y)\n",
    "   - RÂ²: fraction of variance explained\n",
    "\n",
    "**Next time:** Multiple regression with more than one feature!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
