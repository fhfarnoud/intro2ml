{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", and remove `raise NotImplementedError()`.\n",
    "\n",
    "Do not modify cells starting with \"\"\"Check\"\"\". These are used for grading. Some of these provide tests for you to check your code; You should execute these but not change them.\n",
    "\n",
    "When you are asked to write a function or put the results in a variable, it is **not** sufficient to print the results.\n",
    "\n",
    "Finally, provide your name, computing ID, and collaborators (including any GenAI) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COMPUTING_ID = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Background on Polynomial Regression\n",
    "\n",
    "In this homework, we will explore polynomial regression, which is a rather straightforward extension of linear regression. It can also be viewed as linear regression with engineered features, where instead of just using a feature $x$, we also use its powers $x^2,x^3,\\dotsc$. This allows us to model more complex, non-linear relationships between the input features and the target variable.\n",
    "\n",
    "\n",
    "Compare the following forms:\n",
    "\n",
    "- $y = a_1x + a_2z + b$\n",
    "- $y = a_1x + a_2x^2 + b$\n",
    "\n",
    "In the second model, one of the features is a higher order power. In other words, the function that takes $x$ to $y$ is not linear; it's a polynomial. Despite this change, all methods we discussed for linear regression are still applicable, since the prediction is a linear function of the features $\\{x,x^2\\}$.\n",
    "\n",
    "## Model:\n",
    "Consider a polynomial regression model with features $x,x^2,\\dotsc,x^M$,\n",
    "$$y = a_1 x + a_2 x^2 + \\dotsm+ a_M x^M + b.$$ \n",
    "\n",
    "Consider data of the form \n",
    "\n",
    "$$\\vec x = \\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\vdots\\\\\n",
    "x_N\n",
    "\\end{bmatrix}, \\qquad\n",
    "\\vec y = \\begin{bmatrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "\\vdots\\\\\n",
    "y_N\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We can construct the feature matrix for this model as \n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_1 & x_1^2 & \\dotsm & x_1^M & 1\\\\\n",
    "x_2 & x_2^2 & \\dotsm & x_2^M & 1\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "x_{N} & x_{N}^2 & \\vdots & x_{N}^M & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then, for a given vector \n",
    "$$\n",
    "\\vec{a} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\\\vdots \\\\ a_M \\\\ b\\end{bmatrix}\n",
    "$$\n",
    "of coefficients, the prediction is\n",
    "\n",
    "$$ X \\vec{a}.$$\n",
    "### Optimization:\n",
    "$$\n",
    "\\hat{\\vec{a}} = \\arg \\min_{\\vec{a}} \\| \\hat{y} - (X \\vec{a}) \\|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXejmELXId0b"
   },
   "source": [
    "## Problem 1: Diodes and polynomial regression\n",
    "Our goal in this problem is to predict the current value for a diode (y) at given voltage values (x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1699432749076,
     "user": {
      "displayName": "Caroline Crockett",
      "userId": "09433642866050277161"
     },
     "user_tz": 300
    },
    "id": "3Q7SyDOAC8Ac"
   },
   "outputs": [],
   "source": [
    "# data set-up variables\n",
    "Is = 10**(-13) # amps\n",
    "Vt = 0.025     # volts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1699432840643,
     "user": {
      "displayName": "Caroline Crockett",
      "userId": "09433642866050277161"
     },
     "user_tz": 300
    },
    "id": "1fQkxOxGDtRW",
    "outputId": "65fc9f80-3a65-4dca-acf1-2b98ebe4c576"
   },
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "xmin, xmax = 0, 1\n",
    "npoints = 101\n",
    "x = np.linspace(xmin, xmax, num=npoints)\n",
    "y = Is*(np.exp(x/Vt) - 1)\n",
    "\n",
    "# visualize the dataset\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(10, 3))\n",
    "ax1.plot(x, y)\n",
    "ax1.set_ylim(0, 10)\n",
    "ax1.set_xlabel('VD'); ax1.set_ylabel('ID')\n",
    "# plt.savefig('hw5_diode_model0to1.png')\n",
    "\n",
    "# zoom in on a region of interest\n",
    "#xmin, xmax = 0.6, 0.8\n",
    "x_int = x[60:81]\n",
    "y_int = y[60:81]\n",
    "ax2.plot(x_int, y_int)\n",
    "ax2.set_xlabel('VD'); ax2.set_ylabel('ID')\n",
    "#plt.savefig('hw3_diode_modelzoomed.png')\n",
    "\n",
    "# reshape all the data to be columns\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "x_int = x_int.reshape(-1, 1)\n",
    "y_int = y_int.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1699434273623,
     "user": {
      "displayName": "Caroline Crockett",
      "userId": "09433642866050277161"
     },
     "user_tz": 300
    },
    "id": "pCdggxgQuoN0",
    "nbgrader": {
     "checksum": "7bc5cd76e69e0307f006518aca462068",
     "grade": false,
     "grade_id": "cell-5ae0797078f2e1e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "910972b9-b834-427c-a8cc-cc7b8bb4051f"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# perform polynomial regression for M = 1, 2, 3, 4 for x_int\n",
    "# in each case, find SSE and plot the predicted values \n",
    "\n",
    "# plot the true (idealized) relationship\n",
    "plt.plot(x_int, y_int, label=\"True relationship\", linewidth=6)\n",
    "\n",
    "models = [LinearRegression() for _ in range(4)] # to store the models for use in the next part\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model performed better? Why do you think that was the case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1699434713255,
     "user": {
      "displayName": "Caroline Crockett",
      "userId": "09433642866050277161"
     },
     "user_tz": 300
    },
    "id": "oP4KDI5zGh1K",
    "nbgrader": {
     "checksum": "74d75bd234f7c3ddcdd4c960bd6fa633",
     "grade": false,
     "grade_id": "cell-ec2bd37983ce6416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "e9d2e650-8eb1-427d-d2c0-eab12a9f2a02"
   },
   "outputs": [],
   "source": [
    "# TODO: Train the 4 models as in the previous part on x_int (or reuse the trained models). \n",
    "# But this time, produce and plot predictions for the whole range (x). Find the loss for the full range.\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when a model is used outside of the region it was trained?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model do you recommend? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Polynomial regression and size of data\n",
    "The code for this problem is given. Run it for different values of `ndata` from 4 to 400. Which order do you think performs better for small amount of data? Which ones perform better for large amounts of data? Explain why this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "dtafile = './els_small.dta'\n",
    "df = pd.read_stata(dtafile)\n",
    "df.tail() # print out the last rows of the dataframe\n",
    "df = df[pd.to_numeric(df['bymath'], errors='coerce').notnull()]\n",
    "df = df[pd.to_numeric(df['byread'], errors='coerce').notnull()]\n",
    "df = df[pd.to_numeric(df['byses'], errors='coerce').notnull()]\n",
    "mathscore = np.array(list(df.bymath.values), dtype=float)\n",
    "readscore = np.array(list(df.byread.values), dtype=float)\n",
    "mathscore = mathscore.reshape(-1,1)\n",
    "readscore = readscore.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mathscore\n",
    "y = readscore\n",
    "\n",
    "# set how many data points we want to use for training\n",
    "ndata = 4\n",
    "\n",
    "# get the indeces with unique mathscores so that we can fit a function\n",
    "# (we cannot have a function that has the same x value yield two different y values)\n",
    "inds = np.unique(np.hstack([readscore,mathscore])[:,0], return_index=True)[1]\n",
    "inds = np.sort(inds)\n",
    "\n",
    "# set up our training data\n",
    "xtrain = x[inds][0:ndata]\n",
    "ytrain = y[inds][0:ndata]\n",
    "plt.scatter(xtrain, ytrain, label=\"training data\")\n",
    "\n",
    "# TODO: add validation data \n",
    "nval = 10\n",
    "xval = x[inds][ndata:(ndata+nval)]\n",
    "yval = y[inds][ndata:(ndata+nval)]\n",
    "#plt.scatter(xval, yval, label=\"validation data\")\n",
    "\n",
    "# make up some \"test\" data for plotting more smoothly (result of prediction)\n",
    "xplot = np.linspace(np.min(mathscore), np.max(mathscore), 100).reshape(-1,1)\n",
    "\n",
    "for colors, order in zip(['r','y','c', 'k'], [1,2,4,6]): #)[1, 2, 3, 4]):\n",
    "  # create the data matrix\n",
    "  A = np.hstack([xtrain**p for p in range(1, order+1)])\n",
    "  # do the linear regression\n",
    "  lr = LinearRegression().fit(A, ytrain)\n",
    "  a1, b1 = lr.coef_[0][0], lr.intercept_[0]\n",
    "  print(\"results for order=\", order)\n",
    "\n",
    "  # calculate the loss function over the training interval\n",
    "  l = np.sum((lr.predict(A) - ytrain)**2)/np.sqrt(len(ytrain))\n",
    "  print(\"\\t loss function value is {:.2f}\".format(l))\n",
    "\n",
    "  # TODO: calculate the loss function for validation data\n",
    "  Aval = np.hstack([xval**p for p in range(1, order+1)])\n",
    "  l = np.sum((lr.predict(Aval) - yval)**2)/len(yval)\n",
    "  print(\"\\t validation loss function value is {:.2f}\".format(l))\n",
    "\n",
    "  # do the prediction and update the plot\n",
    "  Aplot = np.hstack([xplot**p for p in range(1, order+1)])\n",
    "  yplot = lr.predict(Aplot)\n",
    "  plt.plot(xplot, yplot, c=colors, label=str(order)+ \" order\")\n",
    "\n",
    "# final plot formatting and saving\n",
    "plt.xlabel(\"math\"); plt.ylabel(\"read\")\n",
    "plt.legend()\n",
    "plt.ylim((np.min(readscore), np.max(readscore)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WxtUOGvUY8ND",
    "34Ks0b8bixsp"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
