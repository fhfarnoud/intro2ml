{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74b1a07",
   "metadata": {},
   "source": [
    "\n",
    "**ðŸ¤– AI Lab Partner Policy: STRICTLY Opt-In Code Generation**\n",
    "\n",
    "In this course, we treat AI tools (like ChatGPT, Gemini, Copilot) as **Lab Partners**, not solution generators. You must use the following prompt to ensure the AI acts responsibly.\n",
    "\n",
    "**1. Copy the text inside the block below**\n",
    "**2. Open your AI Assistant (Gemini, ChatGPT, etc.)**\n",
    "**3. Paste the text to set the rules for the session**\n",
    "\n",
    "> \"I am a student in an Intro to Machine Learning course. Please act as my **ML Lab Partner**.\n",
    "> \n",
    "> **Your Rules:**\n",
    "> \n",
    "> 1. **Code Generation is STRICTLY Opt-In:** You **MUST NOT** generate any runnable Python code unless my message starts with one of the specific prefixes below (`code:` or `output:`).\n",
    ">    * *Default Behavior:* If I ask 'How do I...?' or 'Help me with...', explain the strategy in English, provide pseudocode, or use illustrative examples. Do not generate runnable solution code.\n",
    "> \n",
    "> 2. **The 'code:' Trigger (Logic & Calculation):** \n",
    ">    * When generating code, prioritize simplicity and human readability. Avoid complex syntax.\n",
    ">    * **Constraint:** When I use this trigger, provide **only one single line of code**. Do not write full blocks.\n",
    "> \n",
    "> 3. **The 'output:' Trigger (Formatting & Printing):**\n",
    ">    * Use this ONLY when I request code to print results, format tables, or create plots.\n",
    ">    * **Exception:** For this trigger only, you **MAY** provide full multi-line code blocks to handle the verbose syntax of formatting or plotting.\n",
    "> \n",
    "> 4. **Wait for Me:** After providing the code, stop immediately. Wait for me to run it and ask for the next step.\n",
    "> \n",
    "> 5. **Explain Briefly:** Add a short comment explaining what the code does.\n",
    "> \n",
    "> 6. **Catch Logic Errors:** If I ask for a step that is methodologically wrong (like testing on training data), stop me and explain the error before proceeding.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6: k-Means Properties & Improvements\n",
    "\n",
    "In this notebook, we explore:\n",
    "1. **Initialization Sensitivity**: How bad starts lead to bad clustering.\n",
    "2. **Random Restarts**: Running multiple times and keeping the best.\n",
    "3. **k-Means++**: The smarter initialization (default in sklearn).\n",
    "4. **The Elbow Method**: Choosing $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=500, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, alpha=0.5, c='gray')\n",
    "plt.title(\"Dataset with 4 (hidden) Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn's KMeans\n",
    "\n",
    "In Lecture 5, we implemented k-Means from scratch. In practice, we use `sklearn.cluster.KMeans`.\n",
    "\n",
    "**Basic Usage Pattern:**\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Create the model (specify number of clusters)\n",
    "model = KMeans(n_clusters=K)\n",
    "\n",
    "# 2. Fit the model to data\n",
    "model.fit(X)\n",
    "\n",
    "# 3. Access results\n",
    "model.labels_          # Cluster assignment for each point (array of length N)\n",
    "model.cluster_centers_ # Location of each center (array of shape K x D)\n",
    "model.inertia_         # WCSS (Within-Cluster Sum of Squares)\n",
    "```\n",
    "\n",
    "**Key Parameters:**\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `n_clusters` | Number of clusters $K$ | 8 |\n",
    "| `init` | Initialization method: `'random'` or `'k-means++'` | `'k-means++'` |\n",
    "| `n_init` | Number of random restarts (keeps best) | 10 |\n",
    "| `random_state` | Seed for reproducibility | None |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply k-Means to cluster the dataset X into 4 clusters\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Create a KMeans model with n_clusters=4\n",
    "model = KMeans(...)\n",
    "\n",
    "# Fit the model to X\n",
    "model.fit(...)\n",
    "\n",
    "# Print the WCSS and cluster centers shape\n",
    "print...\n",
    "print...\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your clustering result\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=model.labels_, s=30, cmap='viridis', alpha=0.6)\n",
    "plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], \n",
    "            c='red', s=200, marker='*', edgecolor='black', linewidth=2)\n",
    "plt.title(f\"Your k-Means Result (WCSS: {model.inertia_:.1f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Initialization Sensitivity\n",
    "\n",
    "k-Means starts by randomly selecting $K$ initial centers. Because the algorithm only finds a **local optimum**, different starting points can lead to very different final clusteringsâ€”some good, some bad.\n",
    "\n",
    "To demonstrate this, we'll run k-Means **6 times** with different random seeds. We use `n_init=1` to disable sklearn's default behavior of running multiple restarts by itself. We will also set `init='random'` to ensure the same random initialization each time (rather than sklearn's default of k-means++)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "wcss_values = []\n",
    "for i in range(len(axes)):\n",
    "    ax = axes[i]\n",
    "    # YOUR CODE HERE\n",
    "    # TODO: Fit the model and append the WCSS to wcss_values\n",
    "    seed = ...\n",
    "    kmeans = KMeans(...)\n",
    "    kmeans.fit(...)\n",
    "    wcss_values.append(...)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ax.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, s=20, cmap='viridis', alpha=0.6)\n",
    "    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "               c='red', s=150, marker='*')\n",
    "    ax.set_title(f\"Seed {seed} | WCSS: {kmeans.inertia_:.1f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWCSS Range: {min(wcss_values):.1f} (best) to {max(wcss_values):.1f} (worst)\")\n",
    "print(f\"Variation: {(max(wcss_values) - min(wcss_values)) / min(wcss_values) * 100:.1f}% difference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Different random starts lead to *very* different results. Some seeds get stuck in bad local optima!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Random Restarts\n",
    "\n",
    "The standard fix: run k-Means multiple times and keep the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random restarts: just use n_init parameter\n",
    "n_restarts = 10\n",
    "model = KMeans(n_clusters=4, init='random', n_init=n_restarts, random_state=42)\n",
    "model.fit(X)\n",
    "\n",
    "print(f\"Best WCSS from {n_restarts} restarts: {model.inertia_:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the best result\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=model.labels_, s=30, cmap='viridis', alpha=0.6)\n",
    "plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], \n",
    "            c='red', s=200, marker='*')\n",
    "plt.title(f\"Best of {n_restarts} Restarts (WCSS: {model.inertia_:.1f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. k-Means++ Initialization\n",
    "\n",
    "Instead of picking initial centers completely at random, **k-Means++** spreads them out:\n",
    "1. Choose the first center randomly from the data points\n",
    "2. For each subsequent center, pick a point with probability proportional to its squared distance from the nearest existing center\n",
    "\n",
    "This simple change makes k-Means much more likely to find a good solution on the first try. Scikit-learn uses `init='k-means++'` by default.\n",
    "\n",
    "Let's compare both initialization methods side-by-side using the same random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare random vs k-means++ initialization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# TODO: Create and fit KMeans with K=4, random initialization, n_init=1, and a given seed\n",
    "kmeans_random = KMeans(...)\n",
    "kmeans_random.fit(...)\n",
    "#\n",
    "# TODO: Create and fit KMeans with K=4, 'k-means++', n_init=1, and a given seed\n",
    "kmeans_pp = KMeans(...)\n",
    "kmeans_pp.fit(...)\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Plot random init result\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=kmeans_random.labels_, s=30, cmap='viridis')\n",
    "axes[0].scatter(kmeans_random.cluster_centers_[:, 0], kmeans_random.cluster_centers_[:, 1], \n",
    "                c='red', s=200, marker='*')\n",
    "axes[0].set_title(f\"Random Init (WCSS: {kmeans_random.inertia_:.1f})\")\n",
    "\n",
    "# Plot k-means++ result\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=kmeans_pp.labels_, s=30, cmap='viridis')\n",
    "axes[1].scatter(kmeans_pp.cluster_centers_[:, 0], kmeans_pp.cluster_centers_[:, 1], \n",
    "                c='red', s=200, marker='*')\n",
    "axes[1].set_title(f\"k-Means++ Init (WCSS: {kmeans_pp.inertia_:.1f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Random init WCSS: {kmeans_random.inertia_:.1f}\")\n",
    "print(f\"k-Means++ WCSS:   {kmeans_pp.inertia_:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Means++ usually gives better results, even with a single run!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. The Elbow Method\n",
    "\n",
    "How do we choose $K$ when we don't know the true number of clusters? \n",
    "\n",
    "**Key insight:** As $K$ increases, WCSS always decreases (more clusters = points closer to centers). But at some point, adding more clusters gives diminishing returns.\n",
    "\n",
    "The **Elbow Method**:\n",
    "1. Run k-Means for $K = 1, 2, 3, \\ldots$\n",
    "2. Plot WCSS vs $K$\n",
    "3. Look for the \"elbow\"â€”where the curve bends and WCSS stops dropping sharply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute WCSS for K=1 to K=10 and store in wcss_values\n",
    "\n",
    "# YOUR CODE HERE\n",
    "k_values = ...\n",
    "wcss_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    ...\n",
    "    wcss_values.append(...)\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Print results\n",
    "for k, wcss in zip(k_values, wcss_values):\n",
    "    print(f\"K={k}: WCSS = {wcss:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, wcss_values, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title('The Elbow Method', fontsize=14)\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight the elbow (at K=4, which we know is correct)\n",
    "plt.axvline(x=4, color='red', linestyle='--', label='Elbow at K=4')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The elbow is at K=4**, which matches the true number of clusters in our data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvMacPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
